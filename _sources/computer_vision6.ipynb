{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================#\n",
    "#    Drowsiness Detection   #\n",
    "#   with Python and OpenCV  #\n",
    "#===========================#\n",
    "#    Konstantinos Thanos    #\n",
    "#    Mathematician, Msc     #\n",
    "#===========================#\n",
    "\n",
    "# Import packages\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "im = cv2.imread('Resources/coffee_break.png')\n",
    "\n",
    "width = 100\n",
    "height = 100\n",
    "dim = (width, height)\n",
    " \n",
    "# resize image\n",
    "image = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
    " \n",
    "\n",
    "'''\n",
    "Eye Aspect Ratio (E.A.R.)\n",
    "Function to calculate eye aspect ratio as in paper :\n",
    "\"Real-Time Eye Blink Detection using Facial Landmarks [Soukupova, Cech]\"             \n",
    "Landmarks |   0  1  2  3  4  5\n",
    " Left Eye : [36,37,38,39,40,41]\n",
    "Right Eye : [42,43,44,45,46,47]\n",
    "'''\n",
    "def eye_aspect_ratio(eye):\n",
    "     # Vertical distances\n",
    "     dist1 = dist.euclidean(eye[1], eye[5]) # P2-P6\n",
    "     dist2 = dist.euclidean(eye[2], eye[4]) # P3-P5\n",
    "     # Horiontal distance\n",
    "     dist3 = dist.euclidean(eye[0], eye[3]) # P1-P4\n",
    "\n",
    "     # Eye Aspect Ratio (E.A.R.)\n",
    "     ear = (dist1 + dist2) / (2.0 * dist3)\n",
    "\n",
    "     return ear\n",
    "\n",
    "\n",
    "'''\n",
    "Lips Aspect Ratio (L.A.R.)\n",
    "Function to calculate lips aspect ratio in the same way as in E.A.R.\n",
    "Landmarks |   0  1  2  3  4  5  6  7\n",
    "     Lips : [60,61,62,63,64,65,66,67]\n",
    "'''\n",
    "def lips_aspect_ratio(lips):\n",
    "     # Vertical distance\n",
    "     dist1 = dist.euclidean(lips[2], lips[6]) # L3-L7\n",
    "     # Horiontal distance\n",
    "     dist2 = dist.euclidean(lips[0], lips[4]) # L1-L5\n",
    "\n",
    "     # Lips Aspect Ratio (L.A.R.)\n",
    "     lar = float(dist1/dist2)\n",
    "\n",
    "     return lar\n",
    "    \n",
    "'''\n",
    "Facial Landmarks for any face part\n",
    "Function to calculate facial landmark point coordinates (x,y),\n",
    "draw them on frame and return a numpy array with the corresponding points\n",
    "'''\n",
    "def draw_landmarks(face_part, landmarks):\n",
    "     landmarks_list = []\n",
    "     for point in face_part:\n",
    "          x, y = landmarks.part(point).x, landmarks.part(point).y\n",
    "          landmarks_list.append([x,y])\n",
    "          cv2.circle(frame, (x,y), 2, (0,0,255), -1)\n",
    "          \n",
    "     return np.array(landmarks_list)\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Resources/shape_predictor_68_face_landmarks.dat')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     # Capture the image from the webcam\n",
    "#     ret, image = cap.read()\n",
    "#     # Convert the image color to grayscale\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     # Detect the face\n",
    "#     rects = detector(gray, 1)\n",
    "#     # Detect landmarks for each face\n",
    "#     for rect in rects:\n",
    "#         # Get the landmark points\n",
    "#         shape = predictor(gray, rect)\n",
    "# \t# Convert it to the NumPy Array\n",
    "#         shape_np = np.zeros((68, 2), dtype=\"int\")\n",
    "#         for i in range(0, 68):\n",
    "#             shape_np[i] = (shape.part(i).x, shape.part(i).y)\n",
    "#         shape = shape_np\n",
    "\n",
    "#         # Display the landmarks\n",
    "#         for i, (x, y) in enumerate(shape):\n",
    "# \t    # Draw the circle to mark the keypoint \n",
    "#             cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "\t\t\n",
    "#     # Display the image\n",
    "#     cv2.imshow('Landmark Detection', image)\n",
    "\n",
    "#     # Press the escape button to terminate the code\n",
    "#     if cv2.waitKey(10) == 27:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "\n",
    "\n",
    "\n",
    "# Text settings\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.7\n",
    "\n",
    "# Initializations\n",
    "frames = 0\n",
    "\n",
    "# ear & lar, threshold values\n",
    "ear_thresh = 0.15\n",
    "lar_thresh = 0.3\n",
    "\n",
    "# Blink initializations\n",
    "blink_counter, total_blinks = 0, 0\n",
    "# Yawn initializations\n",
    "yawn_counter, total_yawns = 0, 0\n",
    "\n",
    "while True:\n",
    "     _, frame = cap.read()\n",
    "     frame = cv2.flip(frame, 1) # May not be necessary\n",
    "     h, w = frame.shape[: 2]    # Height and Width of frame\n",
    "     \n",
    "     frames += 1\n",
    "\n",
    "     # Grayscale\n",
    "     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "     # Detect faces in the gray frame\n",
    "     faces = detector(gray, 0)\n",
    "\n",
    "     # Loop through each face\n",
    "     for face in faces:\n",
    "          # Determine facial landmarks\n",
    "          facial_landmarks = predictor(gray, face)\n",
    "\n",
    "          # Landmark indexes for eyes and lips\n",
    "          left_eye = [36,37,38,39,40,41]\n",
    "          right_eye = [42,43,44,45,46,47]\n",
    "          \n",
    "          lips = [60,61,62,63,64,65,66,67]\n",
    "\n",
    "          # Convert to numpy array the above lists and\n",
    "          # draw the corresponding facial landmark points on frame\n",
    "          left_eye_points = draw_landmarks(left_eye, facial_landmarks)\n",
    "          right_eye_points = draw_landmarks(right_eye, facial_landmarks)\n",
    "\n",
    "          lips_points = draw_landmarks(lips, facial_landmarks)\n",
    "\n",
    "          # Find and draw the convex hulls of left and right eye, and lips\n",
    "          left_eye_hull = cv2.convexHull(left_eye_points)      \n",
    "          cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1)\n",
    "          \n",
    "          right_eye_hull = cv2.convexHull(right_eye_points)\n",
    "          cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "\n",
    "          lips_hull = cv2.convexHull(lips_points)\n",
    "          cv2.drawContours(frame, [lips_hull], -1, (0, 255, 0), 1)\n",
    "\n",
    "          # Calculate E.A.R. and L.A.R.\n",
    "          left_ear = eye_aspect_ratio(left_eye_points)    # Left eye aspect ratio\n",
    "          right_ear =  eye_aspect_ratio(right_eye_points) # Right eye aspect ratio\n",
    "          ear = (left_ear + right_ear) / 2.0              # Average eye aspect ratio\n",
    "          cv2.putText(frame, \"E.A.R. : {:.2f}\".format(ear), (10,30), font, font_scale, (0,0,255), 2)\n",
    "\n",
    "          lar = lips_aspect_ratio(lips_points) # Lips aspect ratio\n",
    "          cv2.putText(frame, \"L.A.R. : {:.2f}\".format(lar), (10,90), font, font_scale, (0,0,255), 2)\n",
    "\n",
    "          # Check for blinks or yawns\n",
    "          # BLINK\n",
    "          if ear < ear_thresh:\n",
    "               blink_counter += 1\n",
    "          else:\n",
    "               if blink_counter > 3:\n",
    "                    total_blinks += 1\n",
    "               blink_counter = 0\n",
    "          cv2.putText(frame, \"Blinks: {}\".format(total_blinks), (10, 50), font, font_scale, (0, 0, 255), 2)\n",
    "\n",
    "          # YAWN\n",
    "          if lar > lar_thresh:\n",
    "               yawn_counter += 1\n",
    "          else:\n",
    "               if yawn_counter > 1:\n",
    "                    total_yawns += 1\n",
    "               yawn_counter = 0\n",
    "          cv2.putText(frame, \"Yawns: {}\".format(total_yawns), (10, 110), font, font_scale, (0, 0, 255), 2)\n",
    "          \n",
    "          # Drowsiness Detection\n",
    "          if total_yawns > 2 or total_blinks > 3:\n",
    "               frame[20:120, w-120:w-20] = image # Show coffee break image\n",
    "               cv2.putText(frame, \"ALERT\", (w-120, 160), font, 1.2, (0, 0, 255), 4)\n",
    "\n",
    "     cv2.imshow('Frame', frame)\n",
    "     key = cv2.waitKey(1)\n",
    "     if key == 27:\n",
    "          break\n",
    "     if key==ord('r') or key==ord('R'):\n",
    "          total_blinks, total_yawns = 0, 0 # Reset calculations by pressing 'r' or 'R'\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "enable_chalkboard": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
